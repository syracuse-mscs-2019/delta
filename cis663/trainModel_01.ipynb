{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training & Data Org Functions\n",
    "### Begin with loading data & libs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import normalize\n",
    "BATCH_SIZE=2\n",
    "# The following lines adjust the granularity of reporting. \n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = \"{:.1f}\".format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_01 = pd.read_csv(filepath_or_buffer=\"./trainset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get some basic info on the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainset_01.head()\n",
    "#trainset_01.describe()\n",
    "#trainset_01.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Definitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fbank(item):\n",
    "    a = np.load(item)\n",
    "    a = np.resize(a, (2900,10,1))\n",
    "    return a\n",
    "def load_data(input_file):\n",
    "    dfData = pd.read_csv(input_file)\n",
    "    dfLabels = dfData['Subject'].astype('category')\n",
    "    dfFiles = dfData['FileName']\n",
    "    le = LabelEncoder()\n",
    "    targets = le.fit_transform(dfLabels)\n",
    "    inputs = []\n",
    "    for i in range(0, dfFiles.shape[0]):\n",
    "        inputs.append(get_fbank(dfFiles.at[i]))\n",
    "    inputs = np.stack(inputs)\n",
    "    #xmin = inputs.min()\n",
    "    #xmax = inputs.max()\n",
    "    #inputs = (inputs-xmin)/(xmax-xmin)\n",
    "    return inputs, tf.keras.utils.to_categorical(targets), len(np.unique(targets))\n",
    "def plot_the_loss_curve(epochs, rmse):\n",
    "  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
    "  plt.figure()\n",
    "  plt.xlabel(\"Epoch\")\n",
    "  plt.ylabel(\"Root Mean Squared Error\")\n",
    "  plt.plot(epochs, rmse, label=\"Loss\")\n",
    "  plt.legend()\n",
    "  plt.ylim([rmse.min()*0.94, rmse.max()* 1.05])\n",
    "  plt.show()  \n",
    "def create_model(my_learning_rate, feature_layer):\n",
    "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
    "  # Most simple tf.keras models are sequential.\n",
    "  model = tf.keras.models.Model(inputs=ilayer, outputs=olayer)\n",
    "  # Add the layer containing the feature columns to the model.\n",
    "  model.add(feature_layer)\n",
    "  # Add one linear layer to the model to yield a simple linear regressor.\n",
    "  model.add(tf.keras.layers.Dense(units=1, input_shape=(1,)))\n",
    "  # Construct the layers into a model that TensorFlow can execute.\n",
    "  model.compile(optimizer=\"Adam\",\n",
    "                loss=\"categorical_crossentropy\",\n",
    "                metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "  return model\n",
    "def train_model(model, dataset, epochs, batch_size, label_name):\n",
    "  \"\"\"Feed a dataset into the model in order to train it.\"\"\"\n",
    "  features = {name:np.array(value) for name, value in dataset.items()}\n",
    "  label = np.array(features.pop(label_name))\n",
    "  history = model.fit(x=features, y=label, batch_size=batch_size,\n",
    "                      epochs=epochs, shuffle=True)\n",
    "  # The list of epochs is stored separately from the rest of history.\n",
    "  epochs = history.epoch\n",
    "  # Isolate the mean absolute error for each epoch.\n",
    "  hist = pd.DataFrame(history.history)\n",
    "  rmse = hist[\"root_mean_squared_error\"]\n",
    "  return epochs, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "inputs, targets, categories = load_data('./trainset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 2900, 10, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 2898, 8, 8)        80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1449, 4, 8)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1447, 2, 16)       1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 723, 1, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 11568)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1480832   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 78)                10062     \n",
      "=================================================================\n",
      "Total params: 1,492,142\n",
      "Trainable params: 1,492,142\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "386/386 [==============================] - 11s 28ms/step - loss: 4.6748\n",
      "Epoch 2/10\n",
      "386/386 [==============================] - 11s 28ms/step - loss: 4.3679\n",
      "Epoch 3/10\n",
      "386/386 [==============================] - 10s 27ms/step - loss: 4.3753\n",
      "Epoch 4/10\n",
      "386/386 [==============================] - 11s 28ms/step - loss: 3.7304\n",
      "Epoch 5/10\n",
      "386/386 [==============================] - 10s 27ms/step - loss: 2.3406\n",
      "Epoch 6/10\n",
      "386/386 [==============================] - 11s 27ms/step - loss: 1.1660\n",
      "Epoch 7/10\n",
      "386/386 [==============================] - 12s 30ms/step - loss: 0.6206\n",
      "Epoch 8/10\n",
      "386/386 [==============================] - 12s 30ms/step - loss: 0.2997\n",
      "Epoch 9/10\n",
      "386/386 [==============================] - 12s 31ms/step - loss: 0.1978\n",
      "Epoch 10/10\n",
      "386/386 [==============================] - 12s 31ms/step - loss: 0.1394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f76347b0cf8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "ilayer = tf.keras.layers.Input(shape=(2900,10,1), name=\"input\")\n",
    "x = tf.keras.layers.Conv2D(8, (3,3))(ilayer)\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=2)(x)\n",
    "x = tf.keras.layers.Conv2D(16, (3,3))(x)\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=(2,1), strides=2)(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "olayer = tf.keras.layers.Dense(categories, activation=\"softmax\", name=\"output\")(x)\n",
    "model = tf.keras.models.Model(inputs=ilayer, outputs=olayer)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\")\n",
    "model.fit(inputs, targets, epochs=10, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
