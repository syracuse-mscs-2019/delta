{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training & Data Org Functions\n",
    "### Begin with loading data & libs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# The following lines adjust the granularity of reporting. \n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = \"{:.1f}\".format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_01 = pd.read_csv(filepath_or_buffer=\"./trainset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get some basic info on the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainset_01.head()\n",
    "#trainset_01.describe()\n",
    "#trainset_01.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Definitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fbank(item):\n",
    "    a = np.load(item)\n",
    "    a = np.resize(a, (5500,40,1))\n",
    "    return a\n",
    "def load_data(input_file):\n",
    "    dfData = pd.read_csv(input_file)\n",
    "    dfLabels = dfData['Subject'].astype('category')\n",
    "    dfFiles = dfData['FileName']\n",
    "    le = LabelEncoder()\n",
    "    targets = le.fit_transform(dfLabels)\n",
    "    inputs = []\n",
    "    for i in range(0, dfFiles.shape[0]):\n",
    "        inputs.append(get_fbank(dfFiles.at[i]))\n",
    "    inputs = np.stack(inputs)\n",
    "    return inputs, tf.keras.utils.to_categorical(targets), len(np.unique(targets))\n",
    "def plot_the_loss_curve(epochs, rmse):\n",
    "  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
    "  plt.figure()\n",
    "  plt.xlabel(\"Epoch\")\n",
    "  plt.ylabel(\"Root Mean Squared Error\")\n",
    "  plt.plot(epochs, rmse, label=\"Loss\")\n",
    "  plt.legend()\n",
    "  plt.ylim([rmse.min()*0.94, rmse.max()* 1.05])\n",
    "  plt.show()  \n",
    "def create_model(my_learning_rate, feature_layer):\n",
    "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
    "  # Most simple tf.keras models are sequential.\n",
    "  model = tf.keras.models.Model(inputs=ilayer, outputs=olayer)\n",
    "  # Add the layer containing the feature columns to the model.\n",
    "  model.add(feature_layer)\n",
    "  # Add one linear layer to the model to yield a simple linear regressor.\n",
    "  model.add(tf.keras.layers.Dense(units=1, input_shape=(1,)))\n",
    "  # Construct the layers into a model that TensorFlow can execute.\n",
    "  model.compile(optimizer=\"Adam\",\n",
    "                loss=\"categorical_crossentropy\",\n",
    "                metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "  return model\n",
    "def train_model(model, dataset, epochs, batch_size, label_name):\n",
    "  \"\"\"Feed a dataset into the model in order to train it.\"\"\"\n",
    "  features = {name:np.array(value) for name, value in dataset.items()}\n",
    "  label = np.array(features.pop(label_name))\n",
    "  history = model.fit(x=features, y=label, batch_size=batch_size,\n",
    "                      epochs=epochs, shuffle=True)\n",
    "  # The list of epochs is stored separately from the rest of history.\n",
    "  epochs = history.epoch\n",
    "  # Isolate the mean absolute error for each epoch.\n",
    "  hist = pd.DataFrame(history.history)\n",
    "  rmse = hist[\"root_mean_squared_error\"]\n",
    "  return epochs, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, targets, categories = load_data('./trainset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 5500, 40, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 5491, 31, 10)      1010      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 2745, 15, 10)      0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 411750)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               52704128  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 78)                10062     \n",
      "=================================================================\n",
      "Total params: 52,715,200\n",
      "Trainable params: 52,715,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      " 25/386 [>.............................] - ETA: 3:50 - loss: 68.4627"
     ]
    }
   ],
   "source": [
    "ilayer = tf.keras.layers.Input(shape=(5500,40,1), name=\"input\")\n",
    "x = tf.keras.layers.Conv2D(10, (10,10))(ilayer)\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=2)(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "olayer = tf.keras.layers.Dense(categories, activation=\"softmax\", name=\"output\")(x)\n",
    "model = tf.keras.models.Model(inputs=ilayer, outputs=olayer)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\")\n",
    "model.fit(inputs, targets, epochs=3, batch_size=1, verbose=1)\n",
    "\n",
    "epochs, rmse = train_model(my_model, train_df, epochs, batch_size, label_name)\n",
    "plot_the_loss_curve(epochs, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
